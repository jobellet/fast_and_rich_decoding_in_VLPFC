{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jobellet/fast_and_rich_decoding_in_VLPFC/blob/main/Download_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebeb955-c861-4540-9249-3df5e55e8c76",
      "metadata": {
        "id": "1ebeb955-c861-4540-9249-3df5e55e8c76"
      },
      "source": [
        "The following dataset was utilized in the study titled \"Decoding rapidly presented visual stimuli from prefrontal ensembles without report nor post-perceptual processing,\" published in the Neuroscience of Consciousness in 2022 (DOI: [10.1093/nc/niac005](https://doi.org/10.1093/nc/niac005)).\n",
        "\n",
        "# Downloading, Renaming, and Cleaning Up the Dataset\n",
        "\n",
        "- The `monkeyA.pkl` dataset contains recordings from Monkey A, encompassing data from both the Prefrontal Cortex (PFC) and Posterior Parietal Cortex (PPC), recorded simultaneously.\n",
        "\n",
        "- The `monkeyH.pkl` dataset includes PFC data for Monkey H, recorded during a session separate from the PPC data found in `monkeyH_PPC.pkl`.\n",
        "\n",
        "In the original dataset, variable names are not intuitive, time scales vary among some variables, and some variables that were not analyzed previously may contain incorrect or unverified information.\n",
        "\n",
        "**The next cell will perform the following operations:**\n",
        "\n",
        "1. **Variable Renaming:** Update column names to be more descriptive, reducing potential confusion.\n",
        "2. **Trial Index Calculation:** Generate a `TrialIndex` to group stimuli into trials where the inter-stimulus interval is less than 600 ms. A new trial is started when this interval is exceeded.\n",
        "3. **Dataframe Cleaning:** Remove unneeded columns such as various saccade metrics and blink details to simplify the dataset.\n",
        "4. **Type Conversion and Corrections:**\n",
        "   - Convert `InterStimulusInterval` from milliseconds to seconds.\n",
        "   - Correct `StimulusDuration` to ensure it maintains only relevant durations when a list is mistakenly passed as a single entry.\n",
        "   - Convert `StimulusPosition`, `StimulusIdentity`, and `RecordingDayIndex` to integers for consistent and easier data handling.\n",
        "\n",
        "These steps will make the data more intuitive for further analysis, with clearly named variables and a streamlined dataset structure.\n",
        "\n",
        "## Execute the following cell to download and clean the datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0501e36f-88bb-4b10-9752-e127f2202c85",
      "metadata": {
        "id": "0501e36f-88bb-4b10-9752-e127f2202c85"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Functions for loading data\n",
        "\n",
        "def get_monkeyA_df():\n",
        "    \"\"\"Load or download the Monkey A dataset from both PFC and PPC.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_pickle('monkeyA.pkl')\n",
        "    except FileNotFoundError:\n",
        "        link_to_monkeyA_data = 'https://figshare.com/ndownloader/files/27869238'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_data, 'monkeyA.pkl')\n",
        "        df = pd.read_pickle('monkeyA.pkl')\n",
        "    return df\n",
        "\n",
        "def get_monkeyH_dfs():\n",
        "    \"\"\"Load or download the Monkey H datasets for PFC and PPC from separate sessions.\"\"\"\n",
        "    try:\n",
        "        dfPFC = pd.read_pickle('monkeyH.pkl')\n",
        "    except FileNotFoundError:\n",
        "        link_to_monkeyH_PFC_data = 'https://figshare.com/ndownloader/files/27946635'\n",
        "        urllib.request.urlretrieve(link_to_monkeyH_PFC_data, 'monkeyH.pkl')\n",
        "        dfPFC = pd.read_pickle('monkeyH.pkl')\n",
        "\n",
        "    try:\n",
        "        dfPPC = pd.read_pickle('monkeyH_PPC.pkl')\n",
        "    except FileNotFoundError:\n",
        "        link_to_monkeyH_PPC_data = 'https://figshare.com/ndownloader/files/28224414'\n",
        "        urllib.request.urlretrieve(link_to_monkeyH_PPC_data, 'monkeyH_PPC.pkl')\n",
        "        try:\n",
        "            dfPPC = pd.read_pickle('monkeyH_PPC.pkl')\n",
        "        except:\n",
        "            !pip3 install pickle5\n",
        "            import pickle5 as pickle\n",
        "            with open('monkeyH_PPC.pkl', \"rb\") as fh:\n",
        "                dfPPC = pickle.load(fh)\n",
        "\n",
        "    return dfPFC, dfPPC\n",
        "\n",
        "def rename_columns(df, name_pairs):\n",
        "    \"\"\"Renames columns of a pandas DataFrame based on a list of name pairs.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame whose columns are to be renamed.\n",
        "        name_pairs (list of tuples): A list where each tuple contains two strings,\n",
        "                                     the first string is the original column name and\n",
        "                                     the second is the new name.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with updated column names.\n",
        "    \"\"\"\n",
        "    rename_dict = {old_name: new_name for old_name, new_name in name_pairs}\n",
        "    return df.rename(columns=rename_dict)\n",
        "\n",
        "def recalculate_trial_id_count(df):\n",
        "    \"\"\"Recalculates 'TrialIDcount' based on the 'TrialID' column where stimuli grouped into the same\n",
        "    trial have 'TrialID' below 300 ms.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame containing 'TrialID'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with updated 'TrialIDcount'.\n",
        "    \"\"\"\n",
        "    # Initialize a counter and a list to store the new 'TrialIDcount' values\n",
        "    trial_counter = 1\n",
        "    trial_id_counts = [1]\n",
        "\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for i, row in df.iterrows():\n",
        "        if i>1:\n",
        "            if df.sesID[i]>df.sesID[i-1]:\n",
        "                trial_counter += 1\n",
        "        if i<len(df)-1:\n",
        "            # If 'TrialID' is less than 300, the next trial will be the same\n",
        "            if row['TrialID'] < 600:\n",
        "                trial_id_counts.append(trial_counter)\n",
        "            else:\n",
        "                trial_counter += 1\n",
        "                trial_id_counts.append(trial_counter)\n",
        "\n",
        "\n",
        "    # Assign the new 'TrialIDcount' values to the DataFrame\n",
        "    df['TrialIDcount'] = trial_id_counts\n",
        "    return df\n",
        "\n",
        "def clean_dataset(df):\n",
        "    \"\"\"Cleans the DataFrame by removing unnecessary columns.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A cleaned DataFrame with irrelevant columns removed.\n",
        "    \"\"\"\n",
        "    columns_to_remove = ['blinks_on', 'blinks_off', 'saccades_on', 'saccades_off', 'saccades_x', 'saccades_y', 'Spikes_phase']\n",
        "\n",
        "    # Group stimuli in trials based on the SOAs\n",
        "    df  = recalculate_trial_id_count(df)\n",
        "\n",
        "    # Correct when the whole duration list got past in each single line\n",
        "    if type(df['duration'][0])== np.ndarray:\n",
        "        durations = []\n",
        "        for ses in np.unique(np.array(df['sesID'])):\n",
        "            durations.append(df['duration'][np.where(np.array(df['sesID'])==ses)[0][0]])\n",
        "        df['duration'] = np.concatenate(durations)\n",
        "\n",
        "    # Convert the SOA in seconds\n",
        "    df['TrialID'] = np.array(df['TrialID']).astype(float)/1000\n",
        "\n",
        "    # Convert the stimulus position in a sequence into integers\n",
        "    df['ItemID'] = np.array(df['ItemID'] ).astype(int)\n",
        "\n",
        "    # Convert the stimulus indetity in a sequence into integers\n",
        "    df['StimID'] = np.array(df['StimID'] ).astype(int)\n",
        "\n",
        "    # Convert the stimulus day index into integers\n",
        "    df['sesID'] = np.array(df['sesID'] ).astype(int)\n",
        "\n",
        "    return df.drop(columns=columns_to_remove, errors='ignore')\n",
        "\n",
        "name_pairs = [\n",
        "    ('Spikes', 'SpikeTimes_vlPFC'),\n",
        "    ('PPC_Spikes', 'SpikeTimes_PPC'),\n",
        "    ('TrialID', 'InterStimulusInterval'),\n",
        "    ('duration', 'StimulusDuration'),\n",
        "    ('ItemID', 'StimulusPosition'),\n",
        "    ('StimID', 'StimulusIdentity'),\n",
        "    ('TrialIDcount', 'TrialIndex'),\n",
        "    ('sesID', 'RecordingDayIndex')\n",
        "]\n",
        "\n",
        "# Load datasets\n",
        "monkeyA_PFC_and_PPC = get_monkeyA_df()\n",
        "monkeyH_PFC, monkeyH_PPC = get_monkeyH_dfs()\n",
        "\n",
        "\n",
        "\n",
        "monkeyA_PFC_and_PPC = clean_dataset(monkeyA_PFC_and_PPC)\n",
        "monkeyA_PFC_and_PPC = rename_columns(monkeyA_PFC_and_PPC, name_pairs)\n",
        "\n",
        "\n",
        "monkeyH_PFC = clean_dataset(monkeyH_PFC)\n",
        "monkeyH_PFC = rename_columns(monkeyH_PFC, name_pairs)\n",
        "\n",
        "\n",
        "monkeyH_PPC = clean_dataset(monkeyH_PPC)\n",
        "monkeyH_PPC = rename_columns(monkeyH_PPC, name_pairs)\n",
        "\n",
        "monkeyA_PFC_and_PPC.to_pickle('cleaned_monkeyA.pkl')\n",
        "monkeyH_PFC.to_pickle('cleaned_monkeyH_PFC.pkl')\n",
        "monkeyH_PPC.to_pickle('cleaned_monkeyH_PPC.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detailed Description of the Cleaned Dataset Variables\n",
        "\n",
        "- **InterStimulusInterval**: Measures the time in seconds between the onset of one stimulus and the onset of the next.\n",
        "\n",
        "- **TrialIndex**: An integer that uniquely identifies each trial. All stimuli presented within the same trial share this index, facilitating the grouping of data by trial.\n",
        "\n",
        "- **RecordingDayIndex**: An integer that uniquely identifies each recording day, allowing analyses to be segmented by specific experimental sessions.\n",
        "\n",
        "- **StimulusIdentity**: A number between 0 and 17 that identifies the specific image displayed during a trial. This identifier is used to correlate specific stimuli with behavioral and neural responses.\n",
        "\n",
        "- **StimulusPosition**: An ordinal number indicating the position of the stimulus within a trial sequence. The first stimulus in a sequence is numbered 1, which is important for studying response patterns to stimulus order.\n",
        "\n",
        "- **StimulusDuration**: Time in seconds that the stimulus is physically present on the screen, as measured by the photodiode.\n",
        "\n",
        "- **SpikeTimes_vlPFC**: Lists the times of neural spikes in seconds, relative to the stimulus occurrence for each of the 96 channels of the vlFPC array. This detailed recording from the Ventrolateral Frontal Parietal Cortex provides insight into neural activity during stimulus presentation.\n",
        "\n",
        "- **SpikeTimes_PPC**: Similar to `SpikeTimes_vlFPC`, but for the Parietal array. This records the spike times in seconds relative to the stimulus occurrence, enabling comparative studies of neural dynamics across different brain regions.\n",
        "\n",
        "Each entry in the **SpikeTimes...** columns is a list of 96 lists. Each of these 96 lists contains the times at which spikes were detected relative to the stimulus onset. The time interval considered for detecting a spike is between -0.1 seconds and 0.7 seconds relative to stimulus onset."
      ],
      "metadata": {
        "id": "CBUO5wLbL0UL"
      },
      "id": "CBUO5wLbL0UL"
    },
    {
      "cell_type": "markdown",
      "id": "7c049d8d-c53e-4947-ac49-3a516f436524",
      "metadata": {
        "tags": [],
        "id": "7c049d8d-c53e-4947-ac49-3a516f436524"
      },
      "source": [
        "# Download on your local machine\n",
        "## If you ran the previous cells in Google Colab and want to download the cleaned dataset to your local machine, run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6ad5cd-0983-425b-8b64-e18de8e50f0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3f6ad5cd-0983-425b-8b64-e18de8e50f0b",
        "outputId": "030070ae-a0f8-4dd8-b3c3-f3fc97ab479e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_73936630-62fc-4177-84a7-a91a59f98ec1\", \"cleaned_monkeyA.pkl\", 789992953)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43eeca62-3131-4901-a60f-e5b8a7893389\", \"cleaned_monkeyH_PFC.pkl\", 243660247)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e8db83c-8c4b-47a9-8bdd-d3300e3e82f3\", \"cleaned_monkeyH_PPC.pkl\", 62931932)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# List of file names to be downloaded\n",
        "file_names = ['cleaned_monkeyA.pkl', 'cleaned_monkeyH_PFC.pkl', 'cleaned_monkeyH_PPC.pkl']\n",
        "\n",
        "# Loop through each file and initiate a download\n",
        "for file_name in file_names:\n",
        "    files.download(file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJvp9cwes2X1"
      },
      "id": "dJvp9cwes2X1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}