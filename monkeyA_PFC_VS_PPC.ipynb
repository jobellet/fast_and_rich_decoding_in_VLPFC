{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monkeyA_PFC_VS_PPC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uQ721ZWwDw5q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jobellet/fast_and_rich_decoding_in_VLPFC/blob/main/monkeyA_PFC_VS_PPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXoS8KnUCD7n",
        "outputId": "abecfae1-084d-41d3-aefc-4e0dfbf75339"
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from matplotlib import pyplot as plt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from scipy import stats\n",
        "import numpy.matlib\n",
        "from skimage.measure import label\n",
        "import seaborn as sb\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['pdf.fonttype'] = 42\n",
        "matplotlib.rcParams['ps.fonttype'] = 42\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['font.family'] = \"Arial\"\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "# functions for loading data\n",
        "# functions for loading data\n",
        "def get_monkeyA_df():\n",
        "    try:\n",
        "        df = pd.read_pickle('monkeyA.pkl')\n",
        "    except:\n",
        "        link_to_monkeyA_data = 'https://ndownloader.figshare.com/files/27869238?private_link=203b69f9ea28fce41084'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_data,'monkeyA.pkl')\n",
        "        df = pd.read_pickle('monkeyA.pkl')\n",
        "    return df\n",
        "\n",
        "# functions for PSTH\n",
        "def getSpikemat(spiketimes,mint=-.1,maxt=.4):\n",
        "    '''\n",
        "    Bin spiketimes at 1 kHz, single stimuli / trials\n",
        "    '''\n",
        "    t_total = int((maxt-mint)*1000) # total time bins\n",
        "    nch = len(spiketimes)\n",
        "    spikemat = np.zeros((nch,t_total)).astype(bool)\n",
        "    for ch in range(nch):\n",
        "        tms = np.round(spiketimes[ch]*1000).astype(int) - 1 #0-indexing\n",
        "        \n",
        "        tms = tms[(tms>=mint*1000) & (tms<maxt*1000)] - int(mint*1000)\n",
        "        if len(tms)>0:\n",
        "            spikemat[ch,tms] = 1\n",
        "   \n",
        "    return spikemat\n",
        "\n",
        "def gen_time_bin(binsize,overlap,mint=-.1,maxt=.4):\n",
        "    all_bins = []\n",
        "    for i in range(int(binsize/overlap)):\n",
        "        all_bins.append(np.arange(mint,maxt,binsize)+overlap*i)\n",
        "    time_bins = np.sort(np.concatenate(all_bins)).astype(int)\n",
        "    return(time_bins)\n",
        "\n",
        "def rate_binning(spike_times,time_bins,binsize):\n",
        "    time_bins = time_bins/1000 # convert in s\n",
        "    binsize = binsize/1000 # convert in s\n",
        "    average = np.zeros((len(spike_times),len(time_bins)))\n",
        "    for i,t in enumerate(time_bins):\n",
        "        \n",
        "        for chan in range(len(spike_times)):\n",
        "            include = (spike_times[chan]>t) & (spike_times[chan]<(t+binsize))\n",
        "            average[chan,i] = sum(include)/binsize\n",
        "    return(average)\n",
        "\n",
        "# function for cluster correction for multiple comparisons\n",
        "def cluster_perm(real_data,permutations,pval_roi_threshold,pval_threshold):\n",
        "    \n",
        "    mean_perm = np.mean(permutations,axis = 0)\n",
        "    std_perm = np.std(permutations,axis = 0)\n",
        "    tval = (real_data-mean_perm)/std_perm\n",
        "    pval = np.mean(np.matlib.repmat(real_data,permutations.shape[0],1) <= permutations,axis = 0)\n",
        "    clusters = label(pval<pval_roi_threshold)\n",
        "    sum_tvals = []\n",
        "    significant_points = np.zeros_like(real_data).astype(bool)\n",
        "    for i in range(max(clusters)):\n",
        "        sum_tvals.append(sum(tval[clusters == (i+1)]))\n",
        "    \n",
        "    max_sum_tvals_perm = np.zeros(permutations.shape[0])\n",
        "    for i in range(permutations.shape[0]):\n",
        "        real_data_perm = permutations[i,:]\n",
        "        tvalperm = (real_data_perm-mean_perm)/std_perm\n",
        "        pvalperm = np.mean(np.matlib.repmat(real_data_perm,permutations.shape[0]-1,1) <= np.delete(permutations,i,axis = 0),axis = 0)\n",
        "        clusters_perm = label(pvalperm<pval_roi_threshold)\n",
        "        sum_tvals_perm = []\n",
        "        for j in range(max(clusters_perm)):\n",
        "            sum_tvals_perm.append(sum(tvalperm[clusters_perm == (j+1)]))\n",
        "        \n",
        "        if len(sum_tvals_perm)>0:\n",
        "            max_sum_tvals_perm[i] = np.max(sum_tvals_perm)\n",
        "    for i in range(max(clusters)):\n",
        "        if np.mean(sum_tvals[i]<max_sum_tvals_perm)<pval_threshold:\n",
        "            significant_points[clusters == (i+1)] = True\n",
        "    return(significant_points)\n",
        "\n",
        "# global parameters\n",
        "nch = 96 # number of channels in the Utah array\n",
        "sf = 30000; # sampling frequency\n",
        "tmin = -100 #ms, time before each stim\n",
        "tmax = 600 #ms, time after each stim\n",
        "\n",
        "# parameters for binning and normalization\n",
        "binsize = 50 #ms\n",
        "overlap = 25 #ms\n",
        "time_bins = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eihfv5gcBUF"
      },
      "source": [
        "# Monkey A\n",
        "\n",
        "## Obtain normalized firing rate from spike time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgTwzb18bNg8"
      },
      "source": [
        "compute_this_step = False # \n",
        "\n",
        "# download data from figshare\n",
        "df = get_monkeyA_df()\n",
        "\n",
        "def get_monkeyA_firing_rate():\n",
        "    try:\n",
        "        Rb = np.load('monkeyA_PFC_raw_firing_rate.npy')\n",
        "        Rc = np.load('monkeyA_PFC_normalized_firing_rate.npy')\n",
        "        \n",
        "    except:\n",
        "        link_to_monkeyA_raw_firing_rate_PFC = 'https://ndownloader.figshare.com/files/28205367?private_link=203b69f9ea28fce41084'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_raw_firing_rate_PFC,'monkeyA_PFC_raw_firing_rate.npy')\n",
        "        \n",
        "        \n",
        "        link_to_monkeyA_nomalized_firing_rate_PFC = 'https://ndownloader.figshare.com/files/28205388?private_link=203b69f9ea28fce41084'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_nomalized_firing_rate_PFC,'monkeyA_PFC_normalized_firing_rate.npy')\n",
        "        Rb = np.load('monkeyA_PFC_raw_firing_rate.npy')\n",
        "        Rc = np.load('monkeyA_PFC_normalized_firing_rate.npy')\n",
        "    \n",
        "    try:\n",
        "        PPC_Rb = np.load('monkeyA_PPC_raw_firing_rate.npy')\n",
        "        PPC_Rc = np.load('monkeyA_PPC_normalized_firing_rate.npy')\n",
        "    except:\n",
        "        link_to_monkeyA_raw_firing_rate_PPC = 'https://ndownloader.figshare.com/files/28205358?private_link=203b69f9ea28fce41084'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_raw_firing_rate_PPC,'monkeyA_PPC_raw_firing_rate.npy')\n",
        "        \n",
        "        link_to_monkeyA_nomalized_firing_rate_PPC = 'https://ndownloader.figshare.com/files/28205364?private_link=203b69f9ea28fce41084'\n",
        "        urllib.request.urlretrieve(link_to_monkeyA_nomalized_firing_rate_PPC,'monkeyA_PPC_normalized_firing_rate.npy')\n",
        "        PPC_Rb = np.load('monkeyA_PPC_raw_firing_rate.npy')\n",
        "        PPC_Rc = np.load('monkeyA_PPC_normalized_firing_rate.npy')\n",
        "    return Rb,Rc,PPC_Rb,PPC_Rc\n",
        "\n",
        "if compute_this_step:\n",
        "    # create PFC PSTH\n",
        "    ntr = len(df) # number of stimuli presentations\n",
        "\n",
        "    nbins = len(time_bins)\n",
        "    Rb = np.zeros((ntr,nch,nbins)) # this will store the firing rate\n",
        "    Rc = np.zeros((ntr,nch,nbins)) # this will store the normalized firing rate\n",
        "    for tr in tqdm(range(ntr)): # loop through every stimuli presentations\n",
        "        Rb[tr,:] = rate_binning(df['Spikes'].iloc[tr],time_bins,binsize)\n",
        "        \n",
        "    ## center each channel\n",
        "    for sesID in np.unique(np.array(df.sesID)):\n",
        "        for ch in range(nch):\n",
        "            Rc[df.sesID == sesID,ch,:] = (Rb[df.sesID == sesID,ch,:] - np.mean(Rb[df.sesID == sesID,ch,:])) / (np.std(Rb[df.sesID == sesID,ch,:]) + 10e-6) # center each channel for each session independentl\n",
        "    np.save('monkeyA_PFC_raw_firing_rate.npy',Rb)\n",
        "    np.save('monkeyA_PFC_normalized_firing_rate.npy',Rc)\n",
        "    \n",
        "    # create PPC PSTH\n",
        "    ntr = len(df) # number of stimuli presentations\n",
        "\n",
        "    nbins = len(time_bins)\n",
        "    PPC_Rb = np.zeros((ntr,nch,nbins)) # this will store the firing rate\n",
        "    PPC_Rc = np.zeros((ntr,nch,nbins)) # this will store the normalized firing rate\n",
        "    for tr in tqdm(range(ntr)): # loop through every stimuli presentations\n",
        "        PPC_Rb[tr,:] = rate_binning(df['PPC_Spikes'].iloc[tr],time_bins,binsize)\n",
        "        \n",
        "    ## center each channel\n",
        "    for sesID in np.unique(np.array(df.sesID)):\n",
        "        for ch in range(nch):\n",
        "            PPC_Rc[df.sesID == sesID,ch,:] = (PPC_Rb[df.sesID == sesID,ch,:] - np.mean(PPC_Rb[df.sesID == sesID,ch,:])) / (np.std(PPC_Rb[df.sesID == sesID,ch,:]) + 10e-6) # center each channel for each session independentl\n",
        "    np.save('monkeyA_PPC_raw_firing_rate.npy',PPC_Rb)\n",
        "    np.save('monkeyA_PPC_normalized_firing_rate.npy',PPC_Rc)\n",
        "else:\n",
        "    Rb,Rc,PPC_Rb,PPC_Rc = get_monkeyA_firing_rate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKgSGkkg8PJX"
      },
      "source": [
        "# Find visually responsive channels in PPC and PFC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzV_y9yL8PJY"
      },
      "source": [
        "def get_usefull_channels(df,Rb,t):\n",
        "    \n",
        "    baseline = np.mean(Rb[:,:,0],axis =0)\n",
        "    live_channels = baseline>1\n",
        "    \n",
        "    all_amp = np.zeros((96,len(t)))\n",
        "\n",
        "    stimuli = np.unique(np.array(df.StimID).astype(int));\n",
        "    \n",
        "    outstat= np.zeros(96).astype(int)\n",
        "    for i in range(96):\n",
        "        if live_channels[i]:\n",
        "            temp = np.zeros((18,len(t)))\n",
        "            variation = np.zeros((18,2))\n",
        "            for stm in stimuli:\n",
        "                indx = np.where(df.StimID == stm)\n",
        "                average_rate = np.mean(np.squeeze(Rb[indx,i,:]),axis = 0)-baseline[i]\n",
        "                temp[stm,:] = abs(average_rate)\n",
        "                \n",
        "                variation[stm,0]=abs(np.mean(average_rate[(t>t[1]) & (t<=50)]))\n",
        "                variation[stm,1]=abs(np.mean(average_rate[(t>=100) & (t<=200)]))\n",
        "            outstat[i] = stats.ttest_rel(variation[:,0],variation[:,1])[0]<-1.9\n",
        "        else:\n",
        "            outstat[i] = 0\n",
        "    \n",
        "    return(outstat)\n",
        "\n",
        "t = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)+50 \n",
        "outPFC = get_usefull_channels(df,Rb,t)\n",
        "outPPC = get_usefull_channels(df,PPC_Rb,t)\n",
        "\n",
        "maximal_chan_num = np.min((sum(outPFC),sum(outPPC)))\n",
        "left_out = np.round(.1*maximal_chan_num).astype(int)\n",
        "RSVP = (np.array(df.TrialID)==100)  # select only stimuli presentation being followed by an other stimulus 100 ms after the onset\n",
        "RSVP = RSVP & np.concatenate(([False],RSVP[:-1])) # select only stimuli presentation being preceded by an other stimulus 100 ms before the onset\n",
        "single_stim = np.array(df.TrialID)>500\n",
        "single_stim = single_stim & np.concatenate(([False],single_stim[:-1]))\n",
        "stims = range(18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ5rl1YA8PJc"
      },
      "source": [
        "# Estimate difference in accuracy between PFC and PPC for isolated stimuli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR3wArbM8PJc"
      },
      "source": [
        "nstim = len(np.unique(df.StimID))\n",
        "\n",
        "t = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)\n",
        "nperm = 50;\n",
        "K = 10 # number of training folds\n",
        "# index\n",
        "\n",
        "accuracy_PPC = np.zeros((nperm,len(t)))\n",
        "accuracy_PFC = np.zeros((nperm,len(t)))\n",
        "\n",
        "nbins = len(t) # number of time bins\n",
        "     \n",
        "if True:#reproduce_all:\n",
        "    Y = np.array(df.StimID).astype(int)\n",
        "    \n",
        "    for perm in tqdm(range(nperm)):\n",
        "        selected_chan = np.where(outPPC.astype(bool))[0];\n",
        "        selected_chan = selected_chan[np.random.permutation(len(selected_chan))][:maximal_chan_num-left_out]\n",
        "        \n",
        "        \n",
        "        training_stims = single_stim\n",
        "\n",
        "        X = PPC_Rc[:,selected_chan,:] # The firing rate\n",
        "        \n",
        "        ntr = X.shape[0]\n",
        "        ntest = int(ntr/K)\n",
        "        shuffle = np.random.permutation(ntr)# permutation of every trial\n",
        "        Coef = np.zeros((nstim,X.shape[1],nbins,K) )# regression coefficient prealocation\n",
        "        Proba = np.zeros((ntr,nstim,nbins))# predictive probability prealocation\n",
        "        for k in range(K):\n",
        "            testind = shuffle[k*ntest:(k+1)*ntest] # index of trial being tested\n",
        "            if k == K-1:\n",
        "                testind = shuffle[k*ntest:] \n",
        "            Ytest = Y[testind].astype(int)\n",
        "            trainind = np.delete(shuffle,np.arange(k*ntest,(k+1)*ntest)) # index of trial being used for training\n",
        "            trainind = trainind[training_stims[trainind]] # Keeping only long ISI \n",
        "            Xtrain = X[trainind,:]\n",
        "            Ytrain = Y[trainind]\n",
        "\n",
        "            for b in range(nbins):\n",
        "                model = LogisticRegression(fit_intercept=False,solver='lbfgs',multi_class='auto',max_iter=10000).fit(Xtrain[:,:,b],Ytrain)\n",
        "                Coef[:,:,b,k] = model.coef_\n",
        "                Proba[testind,:,b] = model.predict_proba(X[testind,:,b])\n",
        "        all_single_stim = np.zeros((18,len(t)))\n",
        "        for n in stims:\n",
        "            # in isolation\n",
        "            isolated = np.argmax(Proba[(df.StimID == n) & single_stim,:],axis = 1) == n\n",
        "            all_single_stim[n,:] = np.mean(isolated, axis = 0)\n",
        "        accuracy_PPC[perm,:] = np.mean(all_single_stim,axis = 0)\n",
        "        \n",
        "        \n",
        "        # PFC accuracy\n",
        "        X = Rc[:,selected_chan,:] # The firing rate\n",
        "        ntr = X.shape[0]\n",
        "        ntest = int(ntr/K)\n",
        "        \n",
        "        Coef = np.zeros((nstim,X.shape[1],nbins,K) )# regression coefficient prealocation\n",
        "        Proba = np.zeros((ntr,nstim,nbins))# predictive probability prealocation\n",
        "        for k in range(K):\n",
        "            testind = shuffle[k*ntest:(k+1)*ntest] # index of trial being tested\n",
        "            if k == K-1:\n",
        "                testind = shuffle[k*ntest:] \n",
        "            Ytest = Y[testind].astype(int)\n",
        "            trainind = np.delete(shuffle,np.arange(k*ntest,(k+1)*ntest)) # index of trial being used for training\n",
        "            trainind = trainind[training_stims[trainind]] # Keeping only long ISI \n",
        "            Xtrain = X[trainind,:]\n",
        "            Ytrain = Y[trainind]\n",
        "\n",
        "            for b in range(nbins):\n",
        "                model = LogisticRegression(fit_intercept=False,solver='lbfgs',multi_class='auto',max_iter=10000).fit(Xtrain[:,:,b],Ytrain)\n",
        "                Coef[:,:,b,k] = model.coef_\n",
        "                Proba[testind,:,b] = model.predict_proba(X[testind,:,b])\n",
        "        all_single_stim = np.zeros((18,len(t)))\n",
        "        for n in stims:\n",
        "            # in isolation\n",
        "            isolated = np.argmax(Proba[(df.StimID == n) & single_stim,:],axis = 1) == n\n",
        "            all_single_stim[n,:] = np.mean(isolated, axis = 0)\n",
        "        accuracy_PFC[perm,:] = np.mean(all_single_stim,axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTLrx7TFMeBG"
      },
      "source": [
        "## Figure S5 A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BkSlt83g8PJc"
      },
      "source": [
        "nperm = 2000\n",
        "real_diff = accuracy_PPC-accuracy_PFC\n",
        "permutdiff = np.zeros((nperm,real_diff.shape[1]))\n",
        "for i in range(nperm):\n",
        "    permutdiff[i,:] = abs(np.mean(np.matlib.repmat(np.sign(np.random.rand(real_diff.shape[0])-.5),real_diff.shape[1],1).transpose()*real_diff))\n",
        "sigpoints = cluster_perm(abs(np.mean(real_diff,axis = 0)),permutdiff,.001,.001)\n",
        "\n",
        "t = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)+50\n",
        "fig,ax = plt.subplots(1,1,figsize = (10,5))\n",
        "\n",
        "high_bound = np.sort(accuracy_PPC,axis = 0)[49,:]\n",
        "low_bound = np.sort(accuracy_PPC,axis = 0)[1,:]\n",
        "ax.fill_between(t,high_bound,low_bound,alpha= 0.7,linewidth = 0,color = [1,0.7,0])\n",
        "ax.plot(t,np.mean(accuracy_PPC, axis = 0),color = [1,0.7,0])\n",
        "\n",
        "high_bound = np.sort(accuracy_PFC,axis = 0)[49,:]\n",
        "low_bound = np.sort(accuracy_PFC,axis = 0)[1,:]\n",
        "ax.fill_between(t,high_bound,low_bound,alpha= 0.5,linewidth = 0,color = [0,0.6,0.8])\n",
        "ax.plot(t,np.mean(accuracy_PFC, axis = 0),color = [0,0.6,0.8])\n",
        "\n",
        "clusters = label(sigpoints)\n",
        "for k in np.arange(1,max(clusters)+1):\n",
        "    ax.plot(t[clusters==k],np.ones(sum(clusters==k))*0, color = 'k',linewidth = 2) \n",
        "\n",
        "ax.set_xlabel('Time from stimulus onset (ms)')\n",
        "ax.set_ylabel('Decoding accuracy')\n",
        "sb.despine()\n",
        "fig.savefig('monkeyA_PFC_VS_PPC_single_stim.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d-Hhax18PJZ"
      },
      "source": [
        "# Estimate difference in accuracy between PFC and PPC for stimuli in RSVP sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3dRyVKI8PJa",
        "outputId": "595986d0-6b45-4061-c24c-5c472b09e35b"
      },
      "source": [
        "nstim = len(np.unique(df.StimID))\n",
        "\n",
        "t = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)\n",
        "nperm = 50;\n",
        "K = 10 # number of training folds\n",
        "# index\n",
        "\n",
        "accuracy_PPC = np.zeros((nperm,len(t)))\n",
        "accuracy_PFC = np.zeros((nperm,len(t)))\n",
        "\n",
        "nbins = len(t) # number of time bins\n",
        "     \n",
        "Y = np.array(df.StimID).astype(int)\n",
        "\n",
        "for perm in tqdm(range(nperm)):\n",
        "    selected_chan = np.where(outPPC.astype(bool))[0];\n",
        "    selected_chan = selected_chan[np.random.permutation(len(selected_chan))][:maximal_chan_num-left_out]\n",
        "    \n",
        "    \n",
        "    training_stims = RSVP\n",
        "\n",
        "    X = PPC_Rc[:,selected_chan,:] # The firing rate\n",
        "    \n",
        "    ntr = X.shape[0]\n",
        "    ntest = int(ntr/K)\n",
        "    shuffle = np.random.permutation(ntr)# permutation of every trial\n",
        "    Coef = np.zeros((nstim,X.shape[1],nbins,K) )# regression coefficient prealocation\n",
        "    Proba = np.zeros((ntr,nstim,nbins))# predictive probability prealocation\n",
        "    for k in range(K):\n",
        "        testind = shuffle[k*ntest:(k+1)*ntest] # index of trial being tested\n",
        "        if k == K-1:\n",
        "            testind = shuffle[k*ntest:] \n",
        "        Ytest = Y[testind].astype(int)\n",
        "        trainind = np.delete(shuffle,np.arange(k*ntest,(k+1)*ntest)) # index of trial being used for training\n",
        "        trainind = trainind[training_stims[trainind]] # Keeping only long ISI \n",
        "        Xtrain = X[trainind,:]\n",
        "        Ytrain = Y[trainind]\n",
        "\n",
        "        for b in range(nbins):\n",
        "            model = LogisticRegression(fit_intercept=False,solver='lbfgs',multi_class='auto',max_iter=10000).fit(Xtrain[:,:,b],Ytrain)\n",
        "            Coef[:,:,b,k] = model.coef_\n",
        "            Proba[testind,:,b] = model.predict_proba(X[testind,:,b])\n",
        "    all_RSVP = np.zeros((18,len(t)))\n",
        "    for n in stims:\n",
        "        # in RSVP\n",
        "        hundreds = np.argmax(Proba[(df.StimID == n) & RSVP,:],axis = 1) == n\n",
        "        all_RSVP[n,:] = np.mean(hundreds, axis = 0)\n",
        "    accuracy_PPC[perm,:] = np.mean(all_RSVP,axis = 0)\n",
        "    \n",
        "    \n",
        "    # PFC accuracy\n",
        "    X = Rc[:,selected_chan,:] # The firing rate\n",
        "    ntr = X.shape[0]\n",
        "    ntest = int(ntr/K)\n",
        "    \n",
        "    Coef = np.zeros((nstim,X.shape[1],nbins,K) )# regression coefficient prealocation\n",
        "    Proba = np.zeros((ntr,nstim,nbins))# predictive probability prealocation\n",
        "    for k in range(K):\n",
        "        testind = shuffle[k*ntest:(k+1)*ntest] # index of trial being tested\n",
        "        if k == K-1:\n",
        "            testind = shuffle[k*ntest:] \n",
        "        Ytest = Y[testind].astype(int)\n",
        "        trainind = np.delete(shuffle,np.arange(k*ntest,(k+1)*ntest)) # index of trial being used for training\n",
        "        trainind = trainind[training_stims[trainind]] # Keeping only long ISI \n",
        "        Xtrain = X[trainind,:]\n",
        "        Ytrain = Y[trainind]\n",
        "\n",
        "        for b in range(nbins):\n",
        "            model = LogisticRegression(fit_intercept=False,solver='lbfgs',multi_class='auto',max_iter=10000).fit(Xtrain[:,:,b],Ytrain)\n",
        "            Coef[:,:,b,k] = model.coef_\n",
        "            Proba[testind,:,b] = model.predict_proba(X[testind,:,b])\n",
        "    all_RSVP = np.zeros((18,len(t)))\n",
        "    for n in stims:\n",
        "        # in RSVP\n",
        "        hundreds = np.argmax(Proba[(df.StimID == n) & RSVP,:],axis = 1) == n\n",
        "        all_RSVP[n,:] = np.mean(hundreds, axis = 0)\n",
        "    accuracy_PFC[perm,:] = np.mean(all_RSVP,axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [2:31:39<00:00, 181.98s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5atRZLIEtWs"
      },
      "source": [
        "## Figure S5 B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cqDtzdeB8PJb"
      },
      "source": [
        "nperm = 2000\n",
        "real_diff = accuracy_PPC-accuracy_PFC\n",
        "permutdiff = np.zeros((nperm,real_diff.shape[1]))\n",
        "for i in range(nperm):\n",
        "    permutdiff[i,:] = abs(np.mean(np.matlib.repmat(np.sign(np.random.rand(real_diff.shape[0])-.5),real_diff.shape[1],1).transpose()*real_diff))\n",
        "sigpoints = cluster_perm(abs(np.mean(real_diff,axis = 0)),permutdiff,.001,.001)\n",
        "\n",
        "t = gen_time_bin(binsize,overlap,mint=tmin,maxt=tmax)+50\n",
        "fig,ax = plt.subplots(1,1,figsize = (10,5))\n",
        "\n",
        "high_bound = np.sort(accuracy_PPC,axis = 0)[49,:]\n",
        "low_bound = np.sort(accuracy_PPC,axis = 0)[1,:]\n",
        "ax.fill_between(t,high_bound,low_bound,alpha= 0.7,linewidth = 0,color = [1,0.7,0])\n",
        "ax.plot(t,np.mean(accuracy_PPC, axis = 0),color = [1,0.7,0])\n",
        "\n",
        "high_bound = np.sort(accuracy_PFC,axis = 0)[49,:]\n",
        "low_bound = np.sort(accuracy_PFC,axis = 0)[1,:]\n",
        "ax.fill_between(t,high_bound,low_bound,alpha= 0.5,linewidth = 0,color = [0,0.6,0.8])\n",
        "ax.plot(t,np.mean(accuracy_PFC, axis = 0),color = [0,0.6,0.8])\n",
        "\n",
        "clusters = label(sigpoints)\n",
        "for k in np.arange(1,max(clusters)+1):\n",
        "    ax.plot(t[clusters==k],np.ones(sum(clusters==k))*0, color = 'k',linewidth = 2) \n",
        "\n",
        "ax.set_xlabel('Time from stimulus onset (ms)')\n",
        "ax.set_ylabel('Decoding accuracy')\n",
        "sb.despine()\n",
        "fig.savefig('monkeyA_PFC_VS_PPC_RSVP.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyPjUJ38PJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}